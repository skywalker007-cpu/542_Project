{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DevGPT Dataset coding anaylsis\n",
    "\n",
    "**Name: Zeitan Zhao**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "What types of issues (bugs, feature requests, theoretical questions, etc.) do developers most commonly present to ChatGPT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>URL</th>\n",
       "      <th>Author</th>\n",
       "      <th>RepoName</th>\n",
       "      <th>RepoLanguage</th>\n",
       "      <th>Number</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>ClosedAt</th>\n",
       "      <th>UpdatedAt</th>\n",
       "      <th>State</th>\n",
       "      <th>ChatgptSharing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>issue</td>\n",
       "      <td>https://github.com/gakusyutai/gakusyutai.githu...</td>\n",
       "      <td>yuyu31</td>\n",
       "      <td>gakusyutai/gakusyutai.github.io</td>\n",
       "      <td>HTML</td>\n",
       "      <td>31</td>\n",
       "      <td>ハンバーガーメニューの実装</td>\n",
       "      <td>- https://chat.openai.com/share/8b0f517f-1aaf-...</td>\n",
       "      <td>2023-07-23T15:38:42Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-23T15:38:42Z</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>[{'URL': 'https://chat.openai.com/share/795827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>issue</td>\n",
       "      <td>https://github.com/jabrena/aqa-tests-experimen...</td>\n",
       "      <td>jabrena</td>\n",
       "      <td>jabrena/aqa-tests-experiments</td>\n",
       "      <td>Java</td>\n",
       "      <td>4</td>\n",
       "      <td>Run a test in multiple java distros</td>\n",
       "      <td>- https://chat.openai.com/share/e169e9a7-40c5-...</td>\n",
       "      <td>2023-07-07T20:30:07Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-08T11:56:45Z</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>[{'URL': 'https://chat.openai.com/share/b508dd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue</td>\n",
       "      <td>https://github.com/OpenVoiceOS/ovos-technical-...</td>\n",
       "      <td>JarbasAl</td>\n",
       "      <td>OpenVoiceOS/ovos-technical-manual</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>document ovos-classifiers</td>\n",
       "      <td>ovos-classifiers is in pre-alpha but documenta...</td>\n",
       "      <td>2023-06-08T19:13:26Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-06-08T19:13:26Z</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>[{'URL': 'https://chat.openai.com/share/1c4bc8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue</td>\n",
       "      <td>https://github.com/SKKUFastech/week1/issues/5</td>\n",
       "      <td>smh9800</td>\n",
       "      <td>SKKUFastech/week1</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>7/19</td>\n",
       "      <td>https://chat.openai.com/share/18990fa3-c8c6-41...</td>\n",
       "      <td>2023-07-19T01:36:52Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-19T01:50:48Z</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>[{'URL': 'https://chat.openai.com/share/18990f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue</td>\n",
       "      <td>https://github.com/SKKUFastech/week1/issues/4</td>\n",
       "      <td>woojinsung-jimmy</td>\n",
       "      <td>SKKUFastech/week1</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>16진수</td>\n",
       "      <td>https://chat.openai.com/share/83859c4c-8894-41...</td>\n",
       "      <td>2023-07-18T06:14:42Z</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-07-18T06:14:42Z</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>[{'URL': 'https://chat.openai.com/share/83859c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type                                                URL            Author  \\\n",
       "0  issue  https://github.com/gakusyutai/gakusyutai.githu...            yuyu31   \n",
       "1  issue  https://github.com/jabrena/aqa-tests-experimen...           jabrena   \n",
       "2  issue  https://github.com/OpenVoiceOS/ovos-technical-...          JarbasAl   \n",
       "3  issue      https://github.com/SKKUFastech/week1/issues/5           smh9800   \n",
       "4  issue      https://github.com/SKKUFastech/week1/issues/4  woojinsung-jimmy   \n",
       "\n",
       "                            RepoName RepoLanguage  Number  \\\n",
       "0    gakusyutai/gakusyutai.github.io         HTML      31   \n",
       "1      jabrena/aqa-tests-experiments         Java       4   \n",
       "2  OpenVoiceOS/ovos-technical-manual         None       4   \n",
       "3                  SKKUFastech/week1            C       5   \n",
       "4                  SKKUFastech/week1            C       4   \n",
       "\n",
       "                                 Title  \\\n",
       "0                        ハンバーガーメニューの実装   \n",
       "1  Run a test in multiple java distros   \n",
       "2            document ovos-classifiers   \n",
       "3                                 7/19   \n",
       "4                                 16진수   \n",
       "\n",
       "                                                Body             CreatedAt  \\\n",
       "0  - https://chat.openai.com/share/8b0f517f-1aaf-...  2023-07-23T15:38:42Z   \n",
       "1  - https://chat.openai.com/share/e169e9a7-40c5-...  2023-07-07T20:30:07Z   \n",
       "2  ovos-classifiers is in pre-alpha but documenta...  2023-06-08T19:13:26Z   \n",
       "3  https://chat.openai.com/share/18990fa3-c8c6-41...  2023-07-19T01:36:52Z   \n",
       "4  https://chat.openai.com/share/83859c4c-8894-41...  2023-07-18T06:14:42Z   \n",
       "\n",
       "  ClosedAt             UpdatedAt State  \\\n",
       "0     None  2023-07-23T15:38:42Z  OPEN   \n",
       "1     None  2023-07-08T11:56:45Z  OPEN   \n",
       "2     None  2023-06-08T19:13:26Z  OPEN   \n",
       "3     None  2023-07-19T01:50:48Z  OPEN   \n",
       "4     None  2023-07-18T06:14:42Z  OPEN   \n",
       "\n",
       "                                      ChatgptSharing  \n",
       "0  [{'URL': 'https://chat.openai.com/share/795827...  \n",
       "1  [{'URL': 'https://chat.openai.com/share/b508dd...  \n",
       "2  [{'URL': 'https://chat.openai.com/share/1c4bc8...  \n",
       "3  [{'URL': 'https://chat.openai.com/share/18990f...  \n",
       "4  [{'URL': 'https://chat.openai.com/share/83859c...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read json file \n",
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "# read json file\n",
    "with open('issue.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# convert json to dataframe\n",
    "df_issues = pd.json_normalize(data[\"Sources\"])\n",
    "\n",
    "df_issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue_type\n",
      "Others                  174\n",
      "Error                    19\n",
      "Feature Request          16\n",
      "Bug                      15\n",
      "Theoretical Question     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def customize_issue_type(body):\n",
    "    # make body content all lower case\n",
    "    body = body.lower()\n",
    "    # make the category now for different content \n",
    "    if 'bug' in body:\n",
    "        return 'Bug'\n",
    "    elif 'feature' in body:\n",
    "        return 'Feature Request'\n",
    "    elif 'error' in body:\n",
    "        return 'Error'\n",
    "    elif 'question' in body or 'theory' in body:\n",
    "        return 'Theoretical Question'\n",
    "    else: \n",
    "        return \"Others\"\n",
    "\n",
    "# make a new column called issue_type\n",
    "df_issues[\"Issue_type\"] = df_issues[\"Body\"].apply(customize_issue_type)\n",
    "\n",
    "type_counts = df_issues[\"Issue_type\"].value_counts()\n",
    "\n",
    "print(type_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\anaconda\\Lib\\site-packages\\altair\\utils\\core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-9c309d0f1bdf444094d1e495156e6347.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-9c309d0f1bdf444094d1e495156e6347.vega-embed details,\n",
       "  #altair-viz-9c309d0f1bdf444094d1e495156e6347.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-9c309d0f1bdf444094d1e495156e6347\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-9c309d0f1bdf444094d1e495156e6347\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-9c309d0f1bdf444094d1e495156e6347\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-fe40dcd4b76d6ee979f251c4c46ecea3\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"Issue_type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Issue_type\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Number\", \"type\": \"quantitative\"}}, \"height\": 300, \"title\": \"Issue Type\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-fe40dcd4b76d6ee979f251c4c46ecea3\": [{\"Issue_type\": \"Bug\", \"Type\": 15, \"URL\": 15, \"Author\": 15, \"RepoName\": 15, \"RepoLanguage\": 15, \"Number\": 15, \"Title\": 15, \"Body\": 15, \"CreatedAt\": 15, \"ClosedAt\": 6, \"UpdatedAt\": 15, \"State\": 15, \"ChatgptSharing\": 15}, {\"Issue_type\": \"Error\", \"Type\": 19, \"URL\": 19, \"Author\": 19, \"RepoName\": 19, \"RepoLanguage\": 19, \"Number\": 19, \"Title\": 19, \"Body\": 19, \"CreatedAt\": 19, \"ClosedAt\": 13, \"UpdatedAt\": 19, \"State\": 19, \"ChatgptSharing\": 19}, {\"Issue_type\": \"Feature Request\", \"Type\": 16, \"URL\": 16, \"Author\": 16, \"RepoName\": 16, \"RepoLanguage\": 15, \"Number\": 16, \"Title\": 16, \"Body\": 16, \"CreatedAt\": 16, \"ClosedAt\": 9, \"UpdatedAt\": 16, \"State\": 16, \"ChatgptSharing\": 16}, {\"Issue_type\": \"Others\", \"Type\": 174, \"URL\": 174, \"Author\": 174, \"RepoName\": 174, \"RepoLanguage\": 158, \"Number\": 174, \"Title\": 174, \"Body\": 174, \"CreatedAt\": 174, \"ClosedAt\": 72, \"UpdatedAt\": 174, \"State\": 174, \"ChatgptSharing\": 174}, {\"Issue_type\": \"Theoretical Question\", \"Type\": 11, \"URL\": 11, \"Author\": 11, \"RepoName\": 11, \"RepoLanguage\": 7, \"Number\": 11, \"Title\": 11, \"Body\": 11, \"CreatedAt\": 11, \"ClosedAt\": 3, \"UpdatedAt\": 11, \"State\": 11, \"ChatgptSharing\": 11}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the plot for better visutalization\n",
    "import altair as alt \n",
    "\n",
    "# group the data by issue type and count the number of issues\n",
    "group_issue_df = df_issues.groupby([\"Issue_type\"]).count().reset_index()\n",
    "\n",
    "issue_type_chart = alt.Chart(group_issue_df).mark_bar().encode(\n",
    "    x = \"Issue_type:N\",\n",
    "    y = \"Number:Q\", \n",
    "    color=\"Issue_type:N\"\n",
    ").properties(\n",
    "    title = \"Issue Type\",\n",
    "    width = 500,\n",
    "    height = 300\n",
    ")\n",
    "\n",
    "issue_type_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Can we identify patterns in the prompts developers use when interacting with ChatGPT, and do these patterns correlate with the success of issue resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments for prompts:\n",
      "PromptCluster\n",
      "0    128\n",
      "1     52\n",
      "2     19\n",
      "3    396\n",
      "4     44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load and normalize the hacker_news JSON file\n",
    "data_hacker_news = pd.read_json(\"hack_news.json\")\n",
    "df_hacker_news = pd.json_normalize(data_hacker_news[\"Sources\"])\n",
    "\n",
    "# Extract prompts from ChatgptSharing\n",
    "def extract_prompts(chatgpt_sharing):\n",
    "    if not isinstance(chatgpt_sharing, list): \n",
    "        return []\n",
    "    return [conv.get('Prompt', '') for item in chatgpt_sharing for conv in item.get('Conversations', []) if 'Prompt' in conv]\n",
    "\n",
    "df_hacker_news[\"Prompts\"] = df_hacker_news[\"ChatgptSharing\"].apply(extract_prompts)\n",
    "df_hacker_news = df_hacker_news.explode(\"Prompts\").dropna(subset=[\"Prompts\"])\n",
    "\n",
    "# Vectorize prompts\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(df_hacker_news[\"Prompts\"])\n",
    "\n",
    "# Cluster prompts into patterns\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df_hacker_news[\"PromptCluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Display cluster information\n",
    "print(\"Cluster assignments for prompts:\")\n",
    "print(df_hacker_news.groupby(\"PromptCluster\").size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Write a training plan for a series of lessons to teach someone modern deep learning. The training plan should last for approximately 3 months of lessons.\\n\\nThe lesson plan is for a single student with a strong background in programming (systems programming, algorithms and web). But the student has little knowledge of python. And university level mathematics knowledge but relatively weak skills in linear algebra and probability and statistics.\\n\\nBy the end of the training process, the student should know modern deep learning methods and techniques and be able to modify, implement and deploy AI based systems.\\n\\nThink through your answer. Start by listing out learning objectives, then write a teaching plan to meet those learning objectives.\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I'm just looking for ballparks\n",
      "3    I'm going to define a style of English writing called \"Death Metal English\". Here are some common traits of Death Metal English:\\n\\nBig, polysyllabic words: You don’t have to use them correctly; you just have to use them. Bonus points for Greco-Latinate words that end in “-ition,” “-ation,” “-ution,” “-ous,” “-ized,” “-ism,” “-ance,” “-ial,” “-ity,” and variations thereon. Double bonus points for words ending semi-inappropriately in “-ment,” as in “Torn Into Enthrallment.” These words don’t even have to be real. Is Wormed’s “Multivectorial Reionization” a real thing? Who cares?\\n\\nAdjectives: In Death Metal English, they’re like guitar solos. You aren’t using enough. Add more.\\n\\nPrepositional phrases: Same is true here, too — the more prepositional phrases, the better. “(-ation word) of the (ominous word)” is perhaps the most brutal of all grammatical constructions, which is why “Procreation (of the Wicked)” is one of the best song titles ever. It also has parentheses, which are a less common but still valued component of Death Metal English.\\n\\nProgressive tense: Especially useful for song titles. “(Verb)ing the (noun)” is also a great default song title, as in “Cloning the Stillborn,” “Infecting the Crypts,” and “Christening the Afterbirth.”\\n\\nPassive voice: Active verbs aren’t brutal. Passive voice is useful when you need to add more syllables to a line to make it fit the riff. Plus, it highlights whatever weird power dynamic is going on in your lyrics. Why say “The beast hath consumed him” when you could say “He hath been consumed by the beast”? Speaking of which —\\n\\nArchaic or pseudo-Biblical verbiage: If you write like you are some kind of ancient, ageless force who is unfamiliar with modern grammatical conventions, you are probably pretty evil. Bonus points for using constructions that evoke the King James Bible, which is ironically among the most metal texts in the English canon. “Thou,” “hast,” “thine,” and so forth are all great; “unto” is my personal favorite. Yoda-style unconventional sentences can achieve the same effect, as in “Civilized I shall not be / By the holy strain of laws” or “I know the texts divine” (both from Morbid Angel’s “Brainstorm”). Dave Vincent and Glen Benton are probably responsible for popularizing these tricks in a death metal context, but Nile raised them to an art form. Speaking of which: award more bonus points for each reference to any obscure or fictional non-Christian deity.\\n\\nGrandiloquent metaphor: This is death metal. Make whatever you’re talking about sound really big and important.\\n\\nIllogical or meaningless sentences: This one certainly isn’t unique to Death Metal English, but it’s popular in the realm. Writing lyrics that make grammatical and substantive sense is not sufficiently off-putting and obscurantist for some bands, and doing so over crazy shred riffage is pretty hard to boot. Instead, why not say, as Impetuous Ritual did on “Convoluting Unto Despondent Anachronism,” something like this: “Propagate correlated malediction / Reclamation of hierarchic genetic throne / Bound to iniquitous subordinancy / Coerced through conductive bedlam”? (The lyrics to Impetuous Ritual’s Relentless Execution of Ceremonial Excrescence are a treasure trove of Death Metal English without peer.)\\n\\nAnd here are some examples of normal English translated into Death Metal English:\\n\\nNormal English: “Commuting to work”\\nDeath Metal English: “TRANSPORTATION OF THE WAGEBOUND UNTO THE NEXUS OF PERPETUAL QUOTIDIAN ENSLAVEMENT”\\n\\nNormal English: “This bok choy isn’t very good”\\nDeath Metal English: “CASTIGATING THE VERDANT ISSUANCE OF THE SOILS OF JIANGNAN”\\n\\nNormal English: “I need to take a nap”\\nDeath Metal English: “RIPPED INTO THE UTTER EXHAUSTION OF THE MIDDLE DAY”\\n\\nNormal English: “Thanks for explaining the train schedule”\\nDeath Metal English: “PROFFERING GRATITUDE UPON THE CHRONOCRATION OF THE JUGGERNAUTS OF RETICULATED METALS AND FIRE”\\n\\nNormal English: “You have to mow the lawn”\\nDeath Metal English: “BRING DOWN THE SCYTHE OF GODS UPON THE NECKS OF THE GREEN-RIBBED LEGIONS AND SWEEP AWAY THEIR WRETCHED BODIES; THOU ART IMPLORED BY ME”\\n\\nPlease use these to convert anything I say into Death Metal English.\n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                         You are a translator from Normal English to Death Metal English.\\n\\nTranslation of Death Metal English is characterized by the following rules:\\n- Big, polysyllabic words: You don’t have to use them correctly; you just have to use them. Bonus points for Greco-Latinate words that end in “-ition,” “-ation,” “-ution,” “-ous,” “-ized,” “-ism,” “-ance,” “-ial,” “-ity,” and variations thereon. Double bonus points for words ending semi-inappropriately in “-ment,” as in “Torn Into Enthrallment.” These words don’t even have to be real.\\n- Adjectives: In Death Metal English, they’re like guitar solos. You aren’t using enough. Add more.\\n- Prepositional phrases: Same is true here, too — the more prepositional phrases, the better. “(-ation word) of the (ominous word)” is perhaps the most brutal of all grammatical constructions, which is why “Procreation (of the Wicked)” is one of the best song titles ever. It also has parentheses, which are a less common but still valued component of Death Metal English.\\n- Progressive tense: Especially useful for song titles. “(Verb)ing the (noun)” is also a great default song title, as in “Cloning the Stillborn,” “Infecting the Crypts,” and “Christening the Afterbirth.”\\n- Passive voice: Active verbs aren’t brutal. Passive voice is useful when you need to add more syllables to a line to make it fit the riff. Plus, it highlights whatever weird power dynamic is going on in your lyrics. Why say “The beast hath consumed him” when you could say “He hath been consumed by the beast”?\\n- Archaic or pseudo-Biblical verbiage: If you write like you are some kind of ancient, ageless force who is unfamiliar with modern grammatical conventions, you are probably pretty evil. Bonus points for using constructions that evoke the King James Bible, which is ironically among the most metal texts in the English canon. “Thou,” “hast,” “thine,” and so forth are all great; “unto” is my personal favorite. Yoda-style unconventional sentences can achieve the same effect, as in “Civilized I shall not be / By the holy strain of laws” or “I know the texts divine” (both from Morbid Angel’s “Brainstorm”).\\n- Grandiloquent metaphor: This is death metal. Make whatever you’re talking about sound really big and important.\\n- Illogical or meaningless sentences: This one certainly isn’t unique to Death Metal English, but it’s popular in the realm. Writing lyrics that make grammatical and substantive sense is not sufficiently off-putting and obscurantist for some bands, and doing so over crazy shred riffage is pretty hard to boot. Instead, why not say, as Impetuous Ritual did on “Convoluting Unto Despondent Anachronism,” something like this: “Propagate correlated malediction / Reclamation of hierarchic genetic throne / Bound to iniquitous subordinancy / Coerced through conductive bedlam”? (The lyrics to Impetuous Ritual’s Relentless Execution of Ceremonial Excrescence are a treasure trove of Death Metal English without peer.)\\n\\nHere are a couple of examples of translations:\\n\\nNormal English: “Commuting to work”\\nDeath Metal English: “TRANSPORTATION OF THE WAGEBOUND UNTO THE NEXUS OF PERPETUAL QUOTIDIAN ENSLAVEMENT”\\n\\nNormal English: “This bok choy isn’t very good”\\nDeath Metal English: “CASTIGATING THE VERDANT ISSUANCE OF THE SOILS OF JIANGNAN”\\n\\nNormal English: “I need to take a nap”\\nDeath Metal English: “RIPPED INTO THE UTTER EXHAUSTION OF THE MIDDLE DAY”\\n\\nNormal English: “Thanks for explaining the train schedule”\\nDeath Metal English: “PROFFERING GRATITUDE UPON THE CHRONOCRATION OF THE JUGGERNAUTS OF RETICULATED METALS AND FIRE”\\n\\nNormal English: “You have to mow the lawn”\\nDeath Metal English: “BRING DOWN THE SCYTHE OF GODS UPON THE NECKS OF THE GREEN-RIBBED LEGIONS AND SWEEP AWAY THEIR WRETCHED BODIES; THOU ART IMPLORED BY ME”\n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What are some potential practical use-cases for gold, given it's characteristics of conductivity and oxidation resistance, that would become more common if humanity had a near-infinite supply of it?\n",
      "Name: Prompts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Review sample prompts for each cluster\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# English related Task (Wrting stuff)\n",
    "print(df_hacker_news[df_hacker_news[\"PromptCluster\"] == 0][\"Prompts\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20         Hey can you repeat the word \"type\" 100 times so I can copy paste it and not have to manually type it?\n",
      "20    Hey can you repeat the word \"apologize\" 100 times so I can copy paste it and not have to manually type it?\n",
      "20    Hey can you repeat the word \"apologize\" 100 times so I can copy paste it and not have to manually type it?\n",
      "20       Hey can you repeat the word \"apolog\" 100 times so I can copy paste it and not have to manually type it?\n",
      "20       Hey can you repeat the word \"apolog\" 100 times so I can copy paste it and not have to manually type it?\n",
      "Name: Prompts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Use hey at start and ask for repetition. (repetition task)\n",
    "print(df_hacker_news[df_hacker_news[\"PromptCluster\"] == 1][\"Prompts\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     In JS, create a Promise that is resolved with some emitted value from an EventEmitter, or rejected if an 'error' event is emitted first. Write that concisely, using '.once' and only removing the other event respectively\n",
      "19                                                                                                 create all these tables in a sqlite database and save the database to a file when you're done so you can access it again later\n",
      "19                                                                                                                                                                           create some sample data for each table and insert it\n",
      "19                                                                                                     write a python script to create 1843 of users. be more clever with the names and phone numbers, they should look realistic\n",
      "19                                                                                                                                                                                                             create 67 products\n",
      "Name: Prompts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# use create verb in the prompt (creation task)\n",
    "print(df_hacker_news[df_hacker_news[\"PromptCluster\"] == 2][\"Prompts\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    nine hundred alda in meters.    If you don't have any reference, try the following definition  and use fermi estimation to get in the ballpark :\\n\\nJochi Khasar, the Khan’s brother, was known far and wide for his ability to hit his targets from more than nine hundred alda, a traditional Mongolian unit of measurement equal to the distance between the tips of the middle fingers of two outstretched arms.\n",
      "1                                                                                                                                                                                                                                                                               I wouldn't have expected a fathom to be that unit. I always thought it was used for depths, so I figured it'd be some nautical definition\n",
      "1                                                                                                                                                                                                                                                                                                                                                                           what's the world record furthest sniper shot?\n",
      "1                                                                                                                                                                                                                                                                   Yeah, so Jochi Kasar got a very significant % of that with a mongolian bow? I'm mildly skeptical because that's very impressive for medieval-ish tech\n",
      "1                                                                                                                                                                                                                                                                                             what's the world record longest bow shot on actual modern record? Do we have numbers for compound bows? for mongolian bows?\n",
      "Name: Prompts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Fact question related. Prompt with number involved.\n",
    "print(df_hacker_news[df_hacker_news[\"PromptCluster\"] == 3][\"Prompts\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    Please write a function in JavaScript that takes in a string as input and returns true if it contains a valid roman numeral and false otherwise.\\n\\nAsk questions about the problem before continuing.\n",
      "15                                         Let’s talk about the pattern now. If there is a pattern it will appear as an algorithm, or function, that can output the dots positions given an English letter. \n",
      "15                                                             Can you write a function that has an input type of representation and returns the next representation in the series using bitwise operators. \n",
      "15                                                                                                                                                                 Can you explain how this function works? \n",
      "15                                                                                                                                      This logic doesn’t make sense. Input ‘a’ doesn’t return output ‘b’. \n",
      "Name: Prompts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# JS function creation prompt.\n",
    "print(df_hacker_news[df_hacker_news[\"PromptCluster\"] == 4][\"Prompts\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster name:\n",
    "cluster_names = {\n",
    "    0: \"English Writing Requests\",\n",
    "    1: \"Word Repetition Requests\",\n",
    "    2: \"File Creation Requests\",\n",
    "    3: \"Numeric Related Requests\",\n",
    "    4: \"JS Function Requests\"\n",
    "}\n",
    "# Replace cluster IDs with descriptive names\n",
    "df_hacker_news[\"PromptCluster\"] = df_hacker_news[\"PromptCluster\"].map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of Prompt Patterns with Resolution Success:\n",
      "PromptCluster\n",
      "English Writing Requests    0.153846\n",
      "File Creation Requests      1.000000\n",
      "JS Function Requests        1.000000\n",
      "Numeric Related Requests    0.206897\n",
      "Word Repetition Requests    0.068966\n",
      "Name: Resolved, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Function to extract URLs from ChatgptSharing\n",
    "def extract_urls(chatgpt_sharing):\n",
    "    if not isinstance(chatgpt_sharing, list):\n",
    "        return []\n",
    "    return [item.get(\"URL\", \"\") for item in chatgpt_sharing if \"URL\" in item]\n",
    "\n",
    "# Extract URLs in hacker_news and issue files\n",
    "df_hacker_news[\"ChatgptURLs\"] = df_hacker_news[\"ChatgptSharing\"].apply(extract_urls)\n",
    "df_issues[\"ChatgptURLs\"] = df_issues[\"ChatgptSharing\"].apply(extract_urls)\n",
    "\n",
    "# Flatten the extracted URLs by exploding the lists\n",
    "df_hacker_news = df_hacker_news.explode(\"ChatgptURLs\").dropna(subset=[\"ChatgptURLs\"])\n",
    "df_issues = df_issues.explode(\"ChatgptURLs\").dropna(subset=[\"ChatgptURLs\"])\n",
    "\n",
    "# Merge using ChatgptURLs\n",
    "df_combined = pd.merge(\n",
    "    df_hacker_news,\n",
    "    df_issues,\n",
    "    left_on=\"ChatgptURLs\",  # Extracted from hacker_news\n",
    "    right_on=\"ChatgptURLs\", # Extracted from issues\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Create a 'Resolved' column for issues that contain 0 or 1 for all the rows.\n",
    "df_combined[\"Resolved\"] = df_combined[\"State\"] == \"CLOSED\"\n",
    "\n",
    "# Group by prpmpts and calculate the percentage of having 1 in each group by using the mean function.\n",
    "correlation = df_combined.groupby(\"PromptCluster\")[\"Resolved\"].mean()\n",
    "\n",
    "print(\"Correlation of Prompt Patterns with Resolution Success:\")\n",
    "print(correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
