{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b930bf78-2ba4-4f18-9e81-52c2598bcc91",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-weight: bold; font-size: 24px;\">\n",
    "    DS542 - DevGPT\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6b9a5-44f5-4eaf-bc7c-3f5abfb4632b",
   "metadata": {},
   "source": [
    "#### Question 7: How accurately can we predict the length of a conversation with ChatGPT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059491d4-374d-4739-96c8-e1faa8a2b369",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "603a8f27-9da6-421b-a298-e37bdc060609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "27d521fb-7b15-40a8-94ae-6c492f2be165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in JSON files\n",
    "discuss_json = pd.read_json('20230727_195954_discussion_sharings.json')\n",
    "issues_json = pd.read_json('20230727_195941_issue_sharings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ccbab91a-8b2c-451d-91f2-96d09c7e03a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'URL_x', 'Author', 'RepoName', 'RepoLanguage', 'Number',\n",
      "       'Title_x', 'Body', 'CreatedAt', 'ClosedAt', 'UpdatedAt', 'Closed',\n",
      "       'UpvoteCount', 'ChatgptSharing', 'URL_y', 'Status',\n",
      "       'DateOfConversation', 'DateOfAccess', 'Title_y', 'NumberOfPrompts',\n",
      "       'TokensOfPrompts', 'TokensOfAnswers', 'Model', 'Conversations',\n",
      "       'HTMLContent', 'Mention_MentionedURL', 'Mention_MentionedProperty',\n",
      "       'Mention_MentionedAuthor', 'Mention_MentionedText',\n",
      "       'Mention_MentionedIsAnswer', 'Mention_MentionedUpvoteCount', 'Prompt',\n",
      "       'Answer', 'ListOfCode'],\n",
      "      dtype='object')\n",
      "0    July 11, 2023\n",
      "1    July 11, 2023\n",
      "2    July 15, 2023\n",
      "3    July 14, 2023\n",
      "4    June 26, 2023\n",
      "Name: DateOfConversation, dtype: object\n",
      "0    https://github.com/deep-foundation/Discussions...\n",
      "1    https://github.com/orgs/deep-foundation/discus...\n",
      "2    https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tut...\n",
      "3    https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tut...\n",
      "4    https://github.com/dtch1997/gpt-text-gym/discu...\n",
      "Name: Mention_MentionedURL, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Normalizes 'Sources' column\n",
    "discuss_df = pd.json_normalize(discuss_json['Sources'], sep='_')\n",
    "\n",
    "# Normalizes 'ChatgptSharing' column\n",
    "discuss_df2 = pd.json_normalize(\n",
    "    discuss_df['ChatgptSharing'].explode(),\n",
    "    sep='_'\n",
    ")\n",
    "\n",
    "# Normalizes and explodes 'Conversations'\n",
    "discuss_df3 = pd.json_normalize(\n",
    "    discuss_df2['Conversations'].explode(),\n",
    "    sep='_'\n",
    ")\n",
    "\n",
    "# Merges dataframes\n",
    "merged_df1 = pd.merge(discuss_df, discuss_df2, left_index=True, right_index=True, how='outer')\n",
    "final_df = pd.merge(merged_df1, discuss_df3, left_index=True, right_index=True, how='outer')\n",
    "print(final_df.columns)\n",
    "\n",
    "date_of_conversation = final_df['DateOfConversation']\n",
    "print(date_of_conversation.head())\n",
    "\n",
    "mentioned_url = final_df['Mention_MentionedURL']\n",
    "print(mentioned_url.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "80315435-f7e2-4f75-a22d-51b1ceee5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179 entries, 0 to 178\n",
      "Data columns (total 34 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Type                          32 non-null     object \n",
      " 1   URL_x                         32 non-null     object \n",
      " 2   Author                        32 non-null     object \n",
      " 3   RepoName                      32 non-null     object \n",
      " 4   RepoLanguage                  27 non-null     object \n",
      " 5   Number                        32 non-null     float64\n",
      " 6   Title_x                       32 non-null     object \n",
      " 7   Body                          32 non-null     object \n",
      " 8   CreatedAt                     32 non-null     object \n",
      " 9   ClosedAt                      4 non-null      object \n",
      " 10  UpdatedAt                     32 non-null     object \n",
      " 11  Closed                        32 non-null     object \n",
      " 12  UpvoteCount                   32 non-null     float64\n",
      " 13  ChatgptSharing                32 non-null     object \n",
      " 14  URL_y                         38 non-null     object \n",
      " 15  Status                        38 non-null     float64\n",
      " 16  DateOfConversation            33 non-null     object \n",
      " 17  DateOfAccess                  33 non-null     object \n",
      " 18  Title_y                       33 non-null     object \n",
      " 19  NumberOfPrompts               33 non-null     float64\n",
      " 20  TokensOfPrompts               33 non-null     float64\n",
      " 21  TokensOfAnswers               33 non-null     float64\n",
      " 22  Model                         33 non-null     object \n",
      " 23  Conversations                 33 non-null     object \n",
      " 24  HTMLContent                   33 non-null     object \n",
      " 25  Mention_MentionedURL          38 non-null     object \n",
      " 26  Mention_MentionedProperty     38 non-null     object \n",
      " 27  Mention_MentionedAuthor       38 non-null     object \n",
      " 28  Mention_MentionedText         38 non-null     object \n",
      " 29  Mention_MentionedIsAnswer     19 non-null     object \n",
      " 30  Mention_MentionedUpvoteCount  19 non-null     float64\n",
      " 31  Prompt                        174 non-null    object \n",
      " 32  Answer                        174 non-null    object \n",
      " 33  ListOfCode                    174 non-null    object \n",
      "dtypes: float64(7), object(27)\n",
      "memory usage: 48.9+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "caf703af-83f7-4f5c-84ea-0f6ba55fe558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>UpvoteCount</th>\n",
       "      <th>Status</th>\n",
       "      <th>NumberOfPrompts</th>\n",
       "      <th>TokensOfPrompts</th>\n",
       "      <th>TokensOfAnswers</th>\n",
       "      <th>Mention_MentionedUpvoteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>537.187500</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>226.842105</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>596.878788</td>\n",
       "      <td>1728.393939</td>\n",
       "      <td>1.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1275.809533</td>\n",
       "      <td>2.962127</td>\n",
       "      <td>69.884277</td>\n",
       "      <td>6.746632</td>\n",
       "      <td>845.003615</td>\n",
       "      <td>2494.059391</td>\n",
       "      <td>0.524265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>136.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>368.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>809.000000</td>\n",
       "      <td>2566.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5758.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>12044.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Number  UpvoteCount      Status  NumberOfPrompts  TokensOfPrompts  \\\n",
       "count    32.000000    32.000000   38.000000        33.000000        33.000000   \n",
       "mean    537.187500     1.750000  226.842105         5.272727       596.878788   \n",
       "std    1275.809533     2.962127   69.884277         6.746632       845.003615   \n",
       "min       1.000000     0.000000  200.000000         1.000000        15.000000   \n",
       "25%       6.750000     1.000000  200.000000         1.000000        41.000000   \n",
       "50%     136.500000     1.000000  200.000000         3.000000       200.000000   \n",
       "75%     368.500000     1.000000  200.000000         6.000000       809.000000   \n",
       "max    5758.000000    17.000000  404.000000        30.000000      3084.000000   \n",
       "\n",
       "       TokensOfAnswers  Mention_MentionedUpvoteCount  \n",
       "count        33.000000                     19.000000  \n",
       "mean       1728.393939                      1.052632  \n",
       "std        2494.059391                      0.524265  \n",
       "min          25.000000                      0.000000  \n",
       "25%         260.000000                      1.000000  \n",
       "50%         496.000000                      1.000000  \n",
       "75%        2566.000000                      1.000000  \n",
       "max       12044.000000                      3.000000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates summary statistics\n",
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f7311f3-03c7-4f4b-b0e6-c31cb1296b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of turns per conversation: 0.9720670391061452\n",
      "                                              Prompt  ConversationTurns\n",
      "0  Can I always use await import instead of plain...                  1\n",
      "1  Can I always use await import instead of plain...                  1\n",
      "2  ===\\nAuthor: JushBJJ\\nName: \"Mr. Ranedeer\"\\nVe...                  1\n",
      "3  [Personalization Options]\\n    Language: [\"Eng...                  1\n",
      "4  You are an agent in a gridworld.\\nThe environm...                  3\n"
     ]
    }
   ],
   "source": [
    "# Number of turns in each conversation\n",
    "final_df['ConversationTurns'] = final_df['Conversations'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Average number of turns\n",
    "average_turns = final_df['ConversationTurns'].mean()\n",
    "print(f\"Average number of turns per conversation: {average_turns}\")\n",
    "print(final_df[['Prompt', 'ConversationTurns']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "32869878-f26f-4315-8ed1-1152c5dd614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Included to avoid error message\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Replaces 'Default' in string columns\n",
    "string_columns = final_df.select_dtypes(include=['object']).columns\n",
    "final_df[string_columns] = final_df[string_columns].replace('Default', np.nan)\n",
    "\n",
    "# Converts columns to numeric\n",
    "columns_to_clean = ['TokensOfPrompts', 'NumberOfPrompts', 'TokensOfAnswers']\n",
    "for col in columns_to_clean:\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n",
    "# Fills NaNs with 0\n",
    "final_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "21aeee44-9392-46c3-85ac-494b974b42b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      can i always use await import instead of plain...\n",
      "1      can i always use await import instead of plain...\n",
      "2      \\nauthor jushbjj\\nname mr ranedeer\\nversion 27...\n",
      "3      personalization options\\n    language english ...\n",
      "4      you are an agent in a gridworld\\nthe environme...\n",
      "                             ...                        \n",
      "174                                             and more\n",
      "175                                                 more\n",
      "176    data lake and data warehouse are bad names the...\n",
      "177                            give me some better names\n",
      "178                               give me some fun names\n",
      "Name: Prompt_clean, Length: 179, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Fills missing values in the 'Prompt' column with empty string\n",
    "final_df['Prompt_clean'] = final_df['Prompt'].fillna('').str.lower().str.replace('[^\\\\w\\\\s]', '', regex=True)\n",
    "print(final_df['Prompt_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0596fd39-b93e-4a38-8c1c-bf9251757dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "42188eff-3d5a-498e-96c3-9185fa1d539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Prompt_clean'] = final_df['Prompt_clean'].astype(str)\n",
    "final_df['Prompt_clean'].apply(nlp)\n",
    "final_df['Prompt_tokens'] = final_df['Prompt_clean'].apply(lambda x: [token.text for token in nlp(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4f982-ecfd-4dcb-8211-1a2d035a2a44",
   "metadata": {},
   "source": [
    "Preprocesses`final_df` data to move forward with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1b8e2aa-5644-43bd-a741-b1d3b9294199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new featue that representes number of words in prompt column\n",
    "final_df['PromptLength'] = final_df['Prompt_clean'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
    "\n",
    "# Defines features and target\n",
    "features = ['TokensOfPrompts', 'PromptLength', 'NumberOfPrompts', 'Model']\n",
    "target = 'ConversationTurns'\n",
    "\n",
    "# Drops rows with missing values\n",
    "final_df.dropna(subset=features + [target], inplace=True)\n",
    "X = final_df[features]\n",
    "y = final_df[target]\n",
    "\n",
    "# Scales \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('model', OneHotEncoder(), ['Model']),  \n",
    "        ('num', StandardScaler(), ['TokensOfPrompts', 'PromptLength', 'NumberOfPrompts'])  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08fbeb-687d-407b-8723-72411e9855ce",
   "metadata": {},
   "source": [
    "Splitting `X` and `y` data and model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1843be38-11a6-4d3e-8bc0-c4d39831488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from Grid Search: {'regressor__max_depth': None, 'regressor__min_samples_leaf': 1, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Splits data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2025)\n",
    "\n",
    "# Pipeline with preprocessing and random forest model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=2025))\n",
    "])\n",
    "\n",
    "# Trains model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters from Grid Search:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822cf877-1cdd-4e5d-9748-ee4bf5893f37",
   "metadata": {},
   "source": [
    "- hyperparameters suggest flexible model that captures complex relationships in the data, but could be prone to overfitting\n",
    "- model could handle a variety of data points b/c able to have deep trees and a high number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "74815abf-15d3-4180-bb53-d1066afcc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "723a75b8-3daf-4294-9b9c-8ba3deb58c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.16\n",
      "root mean squared error: 0.46\n",
      "R-squared: 0.93\n",
      "Mean Cross-Validation MSE: 3.28\n"
     ]
    }
   ],
   "source": [
    "# Calculates mae and rmse\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "\n",
    "print(f\"mean absolute error: {round(mae,2)}\")\n",
    "print(f\"root mean squared error: {round(rmse,2)}\")\n",
    "print(f\"R-squared: {round(r2, 2)}\")\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Mean Cross-Validation MSE: {round(-cv_scores.mean(),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21dadc8-efa2-4f07-808a-281995b48639",
   "metadata": {},
   "source": [
    "- mae of 0.16 is relatively low. predictions are within ~0.16 of the true values on average.\n",
    "- model is quite accurate in predicting conversation turns but could be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56f6a1-e240-47ac-aca3-7f01f9970356",
   "metadata": {},
   "source": [
    "- RMSE indicates that model's predictions deviate from the true values by around 0.46\n",
    "- is slightly higher than the MAE but still suggests the model is reasonably accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d02ef-0ca9-4097-874c-75cce35886d5",
   "metadata": {},
   "source": [
    "- The MSE of 3.93 is significantly higher - model may not generalize as well to new data. Look at XGboost (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfb5a338-348a-4c30-b632-37daa83e135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on full data: [0.975 0.975 2.82  1.185 4.225 4.225 2.79  1.01  1.99  5.09 ]\n"
     ]
    }
   ],
   "source": [
    "# Predicts conversation turns\n",
    "predictions_full = best_model.predict(X)\n",
    "print(f\"Predictions on full data: {predictions_full[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6bb9960f-3d65-40c9-9685-266e84465385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4c33d087-11b4-4787-898e-72da9279ec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preprocessor': ColumnTransformer(transformers=[('model', OneHotEncoder(), ['Model']),\n",
      "                                ('num', StandardScaler(),\n",
      "                                 ['TokensOfPrompts', 'PromptLength',\n",
      "                                  'NumberOfPrompts'])]), 'regressor': RandomForestRegressor(n_estimators=200, random_state=2025)}\n"
     ]
    }
   ],
   "source": [
    "# Checks model inside pipeline\n",
    "print(best_model.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4387dec-b2f8-4ee6-9155-190672f57f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>25.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20</td>\n",
       "      <td>19.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>18.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>13.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10</td>\n",
       "      <td>8.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y  pred_y\n",
       "17  30  25.860\n",
       "32  20  19.405\n",
       "36  20  18.225\n",
       "13  15  13.920\n",
       "22  10   8.470"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "predict_y = best_model.predict(X_train)\n",
    "\n",
    "# Actual vs. predicted vals\n",
    "c_targets = pd.DataFrame(\n",
    "    {\n",
    "        \"y\": y_train,\n",
    "        \"pred_y\": predict_y.tolist(),\n",
    "    }\n",
    ").sort_values(by=\"pred_y\", ascending=False) \n",
    "\n",
    "c_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ac99fc25-8196-4dfa-8a8a-06ba4c75817c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d2ce4082e4a349818bf64f3efcd4c97c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d2ce4082e4a349818bf64f3efcd4c97c.vega-embed details,\n",
       "  #altair-viz-d2ce4082e4a349818bf64f3efcd4c97c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d2ce4082e4a349818bf64f3efcd4c97c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d2ce4082e4a349818bf64f3efcd4c97c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d2ce4082e4a349818bf64f3efcd4c97c\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"point\"}, \"encoding\": {\"tooltip\": [{\"field\": \"y\", \"type\": \"quantitative\"}, {\"field\": \"pred_y\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"y\", \"title\": \"Actual Number of Turns\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"pred_y\", \"title\": \"Predicted Number of Turns\", \"type\": \"quantitative\"}}, \"title\": \"Actual vs Predicted Y Values\"}, {\"mark\": {\"type\": \"line\", \"color\": \"green\"}, \"encoding\": {\"x\": {\"field\": \"y\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-79e44e05b8069e247eb83337cfe9651d\"}, \"height\": 400, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-79e44e05b8069e247eb83337cfe9651d\": [{\"y\": 30, \"pred_y\": 25.86}, {\"y\": 20, \"pred_y\": 19.405}, {\"y\": 20, \"pred_y\": 18.225}, {\"y\": 15, \"pred_y\": 13.92}, {\"y\": 10, \"pred_y\": 8.47}, {\"y\": 7, \"pred_y\": 7.32}, {\"y\": 7, \"pred_y\": 7.085}, {\"y\": 6, \"pred_y\": 5.62}, {\"y\": 5, \"pred_y\": 5.395}, {\"y\": 5, \"pred_y\": 5.09}, {\"y\": 3, \"pred_y\": 2.9}, {\"y\": 3, \"pred_y\": 2.79}, {\"y\": 2, \"pred_y\": 2.04}, {\"y\": 2, \"pred_y\": 1.99}, {\"y\": 2, \"pred_y\": 1.965}, {\"y\": 1, \"pred_y\": 1.195}, {\"y\": 1, \"pred_y\": 1.185}, {\"y\": 1, \"pred_y\": 1.015}, {\"y\": 1, \"pred_y\": 1.01}, {\"y\": 1, \"pred_y\": 1.01}, {\"y\": 1, \"pred_y\": 1.005}, {\"y\": 1, \"pred_y\": 0.975}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}, {\"y\": 0, \"pred_y\": 0.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot of actual vs. pred\n",
    "chart = alt.Chart(c_targets).mark_point().encode(\n",
    "    x=alt.X('y', title=\"Actual Number of Turns\"),\n",
    "    y=alt.Y('pred_y', title=\"Predicted Number of Turns\"),\n",
    "    tooltip=['y', 'pred_y']\n",
    ").properties(width=600, height=400,\n",
    "    title='Actual vs Predicted Y Values'\n",
    ")\n",
    "\n",
    "# Add a line for ideal prediction (y = x)\n",
    "ideal_line = alt.Chart(c_targets).mark_line(color='green').encode(\n",
    "    x='y',\n",
    "    y='y'\n",
    ")\n",
    "\n",
    "final_chart = chart + ideal_line\n",
    "final_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
